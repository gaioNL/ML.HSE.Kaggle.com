{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 0.1-26.11.2017\n",
    "\n",
    "Update 14.11.2017\n",
    "\n",
    "Update 15.12.2017\n",
    "\n",
    "Update 17.12.2017\n",
    "\n",
    "Update 20.12.2017 v0.1 - changed lgb parameters\n",
    "\n",
    "Update 20.12.2017 v0.2 - introduced early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project: predict future sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This challenge serves as final project for the \"How to win a data science competition\" Coursera course.\n",
    "In this competition you will work with a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company. \n",
    "\n",
    "We are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance your data science skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../readonly/final_project_data/'\n",
    "\n",
    "sales    = pd.read_csv(os.path.join(DATA_FOLDER, 'sales_train.csv.gz'))\n",
    "items           = pd.read_csv(os.path.join(DATA_FOLDER, 'items.csv'))\n",
    "item_categories = pd.read_csv(os.path.join(DATA_FOLDER, 'item_categories.csv'))\n",
    "shops           = pd.read_csv(os.path.join(DATA_FOLDER, 'shops.csv'))\n",
    "train           = pd.read_csv(os.path.join(DATA_FOLDER, 'sales_train.csv.gz'), compression='gzip')\n",
    "test           = pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv.gz'), compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"0\">\n",
    "  <li><b>Print the shape of the loaded dataframes </b></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('sales shape %s' % np.str(sales.shape))\n",
    "print ('items shape %s' % np.str(items.shape))\n",
    "print ('item_categories shape %s' % np.str(item_categories.shape))\n",
    "print ('shops shape %s' % np.str(shops.shape))\n",
    "print ('train shape %s' % np.str(train.shape))\n",
    "print ('test shape %s' % np.str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, train & transactions are the same ;-()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.shop_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test.shop_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test.item_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAIO - NOTE. The test set includes a subset of shops & items. I need to find out how the selection has been made to be able to create the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start manipulating & enriching the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the revenues/transaction\n",
    "sales['revenues'] = sales['item_price'] * sales['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the dates splitting day/month/year\n",
    "sales['f_date'] = pd.to_datetime(sales['date'],format='%d.%m.%Y')\n",
    "sales['year'] = sales['f_date'].dt.year\n",
    "sales['month'] = sales['f_date'].dt.month\n",
    "sales['day'] = sales['f_date'].dt.day\n",
    "sales['week'] = sales['f_date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add category description to the items df\n",
    "items_merge = pd.merge(left = items, right = item_categories , left_on = 'item_category_id', right_on = 'item_category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (items_merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add the category to the items sold\n",
    "sales_merge = pd.merge(left = sales,right = items_merge, left_on ='item_id', right_on = 'item_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sales_merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#06.12.2017 - date_block_num is the month number\n",
    "print (sales_merge.date_block_num.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check date range\n",
    "print ('Sale from %s to %s' % (str(sales_merge.f_date.min()),str(sales_merge.f_date.max())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 years & 10 months of sales data. I need to predict the sales in November 2015\n",
    "\n",
    "### Missing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values?\n",
    "sales_merge.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing data, all columns have been populated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to visualize the revenues over the train period.\n",
    "I start grouping by month, shop_id & item_id to reproduct the target grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggrYearMonthShopItem = sales_merge.groupby(['year','month','shop_id','item_id'])[['item_cnt_day']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggrYearMonthShopItem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggrYearMonth = sales_merge.groupby(['year','month'])[['item_cnt_day']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggrYearMonth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RevMonth = pd.Series(aggrYearMonth.item_cnt_day)#, index = aggrYearMonth.month) \n",
    "df_RevMonth.plot(title = \"Items/Month\") \n",
    "plt.xlabel(\"month\") \n",
    "plt.ylabel(\"items\") \n",
    "plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggrMonth = sales_merge.groupby(['date_block_num'])[['item_cnt_day']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aggrMonth.item_cnt_day)\n",
    "plt.title (\"Items/Month\")\n",
    "plt.xlabel(\"month\") \n",
    "plt.ylabel(\"items\") \n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAIO NOTE - there seems to be a pattern in the behaviour across the years\n",
    "\n",
    "I drill down to the weeks to verify the seasonality of the shop sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggrYearWeek = sales_merge.groupby(['year','week'])[['item_cnt_day']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggrYearWeek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RevWeek = pd.Series(aggrYearWeek.item_cnt_day)#, index = aggrYearMonth.month) \n",
    "df_RevWeek.plot(title = \"items/Week\") \n",
    "plt.xlabel(\"week\") \n",
    "plt.ylabel(\"items\") \n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAIO NOTES: \n",
    "\n",
    "* There seems to be some seasonality in the sales, with an indication of simmetry.\n",
    "* The simmetry may indicate strong sales seasonality around festivities.\n",
    "* We can notice a sharp increase followed by a sharp decrease around the spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAIO NOTES: \n",
    "\n",
    "Let's get 1st the Kaggle process right. \n",
    "I will create the shop grouping with the code from Wk3, fit a un-optimized model & make a submission to verify that everything works.\n",
    "Afterwards I will go back to EDA etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "\n",
    "#fix column names\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train on the 1st 32 months & validate on the last month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = all_data['date_block_num']\n",
    "\n",
    "last_block = dates.max() \n",
    "\n",
    "dates_train = dates[dates <  last_block]\n",
    "dates_val  = dates[dates == last_block]\n",
    "\n",
    "X_train = all_data.loc[dates <  last_block]\n",
    "X_val =  all_data.loc[dates == last_block]\n",
    "\n",
    "y_train = all_data.loc[dates <  last_block, 'target'].values\n",
    "y_val =  all_data.loc[dates == last_block, 'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(X,y):\n",
    "    return np.sqrt(mean_squared_error(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st save the data & create the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=np.clip(y_train,0, 20)\n",
    "y_val=np.clip(y_val,0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "#model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "#                              learning_rate=0.05, n_estimators=720,\n",
    "#                              max_bin = 55, bagging_fraction = 0.8,\n",
    "#                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "#                              feature_fraction_seed=9, bagging_seed=9,\n",
    "#                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0\n",
    "              }\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "model_lgb = lgb.train(lgb_params,                     \n",
    "                      lgb_train,\n",
    "                      num_boost_round=300)#,\n",
    "#                      valid_sets=lgb_eval,\n",
    "#                      early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model_lgb.predict(X_train)\n",
    "rmse_train = rmse(y_train, train_preds)\n",
    "\n",
    "val_preds = model_lgb.predict(X_val)\n",
    "rmse_val = rmse(y_val, val_preds)\n",
    "\n",
    "print('Train R-squared is %f' % rmse_train)\n",
    "print('Validation R-squared is %f' % rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.train(lgb_params, lgb.Dataset(all_data_copy, label=y), 100)\n",
    "lgb_RMSE = rmse(model_lgb.predict(all_data_copy),y)\n",
    "print (\"RMSE: %.5f\" % (lgb_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = model_lgb.predict(test)\n",
    "#clip the target values in the range 0-20\n",
    "out_df = pd.DataFrame({'ID': test.ID, 'item_cnt_month': np.clip(y_test,0,20)})\n",
    "# you could use any filename. We choose submission here\n",
    "out_df.to_csv('predict_future_prices_2117.v0.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hw_version": "1.0.0",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
